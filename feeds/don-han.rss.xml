<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Don Han</title><link>https://don-han.github.io/website/</link><description></description><atom:link href="https://don-han.github.io/website/feeds/don-han.rss.xml" rel="self"></atom:link><lastBuildDate>Fri, 18 Sep 2015 00:00:00 -0700</lastBuildDate><item><title>Analysis of Berkeley Crime Rate</title><link>https://don-han.github.io/website/analysis-of-berkeley-crime-rate.html</link><description>&lt;p&gt;&lt;img alt="Total number of crime per hour in Berkeley" src="/images/berkeley_crime1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Created using R&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Don Han</dc:creator><pubDate>Fri, 18 Sep 2015 00:00:00 -0700</pubDate><guid>tag:don-han.github.io,2015-09-18:website/analysis-of-berkeley-crime-rate.html</guid></item><item><title>[HOW-TO] Bash Parallel Programming</title><link>https://don-han.github.io/website/bash-parallel-programming.html</link><description>&lt;p&gt;Parallel programming basically means writing scripts that can process multiple
tasks at the same. This is in contrast to running scripts in a serial order which requires the
previous tasks to be completed before moving onto the next.&lt;/p&gt;
&lt;p&gt;Parallelization can be used to boost the performance, but it requires the tasks
that are going to be parallelized be independent of one another. Therefore, in
this tutorial, we will refer to the function &lt;code&gt;do-something&lt;/code&gt; as a task that can
be safely run in parallel. For didactic purpose, we define &lt;code&gt;do-something&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;-something&lt;span class="o"&gt;(){&lt;/span&gt;
    sleep &lt;span class="nv"&gt;$1&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are several ways of parallelizing a bash script, and each has its own pros
and cons.&lt;/p&gt;
&lt;p&gt;1.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="k"&gt;$(&lt;/span&gt;seq &lt;span class="m"&gt;5&lt;/span&gt; 1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="k"&gt;do&lt;/span&gt;-something &lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is the simplest form of parallelization in bash. &amp;amp; forks each
&lt;code&gt;do-something&lt;/code&gt; task to the background everytime it's called.&lt;/p&gt;
&lt;p&gt;If you run the script, your output should look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Even though our script runs from 5 to 1, &lt;code&gt;do-something&lt;/code&gt; task with the shortest sleeping time gets finished first.&lt;/p&gt;
&lt;p&gt;Also, note the speed improvement. Our serial script runs in &lt;code&gt;5+4+3+2+1=15&lt;/code&gt;
seconds while our parallel should theoretically run in 5 seconds. That's 3 times performance improvement by just attaching &amp;amp;!&lt;/p&gt;
&lt;p&gt;However, there is one critical problem. Imagine, instead of looping through 5 iterations, your script has to loop through 5000 iterations, and your &lt;code&gt;do-something&lt;/code&gt; does something far more intensive. Then, your &amp;amp; can overload the server. Our next method prevents that.&lt;/p&gt;
&lt;p&gt;ADVATAGE: simple&lt;/p&gt;
&lt;p&gt;DISADVANTAGE: can potentially overload the system&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;wait_turn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4
&lt;span class="nv"&gt;j&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="k"&gt;$(&lt;/span&gt;seq &lt;span class="m"&gt;10&lt;/span&gt; 1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="k"&gt;do&lt;/span&gt;-something &lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt;j++ % &lt;span class="nv"&gt;wait_turn&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; 0&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nb"&gt;wait&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="nb"&gt;wait&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;after loop&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Running this, our result should look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;7
8
9
10
3
4
5
6
1
2
after loop
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Can you see the pattern?&lt;/p&gt;
&lt;p&gt;Once our &lt;code&gt;wait&lt;/code&gt; function is called, the shell "waits" until all background tasks
are finished. In this case, a batch of four tasks are forked into the background at a time, and the script waits until all the processes are complete. &lt;/p&gt;
&lt;p&gt;The value of wait_turn has been chosen arbitrarily, so you can fiddle with it to find the right number for your own script. &lt;/p&gt;
&lt;p&gt;A keen observer might have noted the another &lt;code&gt;wait&lt;/code&gt; function after the function.
To illustrate its need, consider a similar script:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;wait_turn=4&lt;/span&gt;
&lt;span class="x"&gt;j=1&lt;/span&gt;
&lt;span class="x"&gt;for i in &lt;/span&gt;&lt;span class="p"&gt;$(&lt;/span&gt;&lt;span class="err"&gt;seq&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;; do&lt;/span&gt;
&lt;span class="x"&gt;    do-something &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;i&lt;/span&gt;&lt;span class="x"&gt; &amp;amp;&lt;/span&gt;
&lt;span class="x"&gt;    if ((j++ % wait_turn == 0)); then&lt;/span&gt;
&lt;span class="x"&gt;        wait&lt;/span&gt;
&lt;span class="x"&gt;    fi&lt;/span&gt;
&lt;span class="x"&gt;done&lt;/span&gt;
&lt;span class="x"&gt;echo &amp;quot;after loop&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Before scrolling down, think what this would output.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;7
8
9
10
3
4
5
6
after loop
1
2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice how our after loop comes before &lt;code&gt;do-something 1&lt;/code&gt; and &lt;code&gt;do-something 2&lt;/code&gt; is
processed. This could be critical if you have an after-loop code that needs the
for loop to completely finish. Likewise, apply &lt;code&gt;wait&lt;/code&gt; fucntion after the for loop for the first method if necessary.&lt;/p&gt;
&lt;p&gt;[[ MORE ON XARG AND PARALLEL COMING ]]&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Don Han</dc:creator><pubDate>Sun, 09 Aug 2015 00:00:00 -0700</pubDate><guid>tag:don-han.github.io,2015-08-09:website/bash-parallel-programming.html</guid></item><item><title>[intro-to] P vs. NP</title><link>https://don-han.github.io/website/intro-to-p-vs-np.html</link><description>&lt;p&gt;NOTE: The following article is intended as a gentle introduction
for the subject, so I have intentionally left out some information that I considered
is out of scope. However, if you are familiar with the subject and if you think
I presented &lt;em&gt;factually wrong&lt;/em&gt; statements, I will greatly appreciate an email
with corrections. Also, if you are confused with my explanation, please feel free to
send me an email with details of where you are confused, so I can make it a bit
more clear. &lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;What exactly are P and NP? Why do we need them?&lt;/h1&gt;
&lt;p&gt;In order to understand the P vs. NP problem, we must understand P and NP first. P
and NP rose from the necessity of matheticians and computer scientists to
describe how much resources, such as time, are needed to solve a decision
problem. A decision problem is defined as any problem that given an input can
determine or &lt;em&gt;decide&lt;/em&gt; with "yes" or "no" answer. For example, given a path and a
budget cost as inputs, the decision problem might output "yes" if the path cost
is equal to or lower than the budget cost. Likewise, the decision problem might output "no" if the path cost is higher than the budget cost. &lt;/p&gt;
&lt;p&gt;To be more precise, P problems are a set of decision problems that can be solved in polynomial
time &lt;em&gt;and&lt;/em&gt; verified in polynomial time. For the decision problem used as an
example above, our verification algorithm may sum up the cost of edges in linear time ( O(n) ) to
compare it with the budget cost while the search algorithms such as DFS/BFS
obtain the path in linear time as wel. On the other hand, NP problems are
a set of decision problems which can be verified in polynomial time, but &lt;em&gt;not
necessarily&lt;/em&gt; solved in polynomial time. &lt;/p&gt;
&lt;p&gt;Although a common misunderstanding is to
conceptualize NP as "&lt;em&gt;not&lt;/em&gt; P", such notion is greatly misleading. Note that NP
problems may or may not be solved in polynomial time. Therefore, NP and P are
not mutually exclusive classes. Rather, P is a subset of NP; all P problems
automatically qualify as NP problems since all P problems satisfy
polynomial-time verification &lt;em&gt;as well as&lt;/em&gt; polynomial-time solution, and since NP
problems only need to fulfill polynomial-time verification, all P problems are NP problems as well.&lt;/p&gt;
&lt;p&gt;For more technical details between P and NP, refer to the extra note.&lt;/p&gt;
&lt;h1&gt;P versus NP&lt;/h1&gt;
&lt;p&gt;Now we can tackle P vs. NP problem. The question simiply asks if P equals to NP
or not. In other words, the problem asks, if a
problem can be verified in a polynomial time, can the problem be solved in
a polynomial time &lt;em&gt;all the time&lt;/em&gt;? That is, are some NP problems inherently
difficult or even impossible to solve in polynomial time, or have we just
not found the fast algorithms &lt;em&gt;yet&lt;/em&gt;? So far, no official proof has been
recognized by the Clay Mathematics Institute, which promises to reward
one million dollars to anyone who can solve the P vs. NP problem. Although the question is simple, the implication is significant. &lt;/p&gt;
&lt;h1&gt;Implications of P = NP&lt;/h1&gt;
&lt;p&gt;If P = NP is proven, then this implies that all problems that can be
verified in polynomial time can also be solved in polynomial time as well. The
impact extends beyond the academic world since many industrial algorithms including
cryptography are written under the assumption that P != NP.&lt;/p&gt;
&lt;p&gt;For example, RSA, which is a widely used cryptosystem to secure data
transmission, exploits P != NP by designing a decryption algorithm that runs in
polynomial time only for those who have the right access (known as a private key). If you
do not have the private key (meaning you do not have access), you would need to solve
the RSA problem, which is a NP problem since there is no known algorithm that
can decrypt encryption in polynomial time.&lt;/p&gt;
&lt;p&gt;However, if P = NP is proven true, this implies that there exists some
algorithms that can solve the RSA problem in polynomial time, meaning any
encrypted message can be decrypted easily by even those who should not have
access if they can find the polynomial-time decryption algorithm, which is not
supposed to exist under the P != NP assumption. &lt;/p&gt;
&lt;p&gt;Obviously, this is a significant security threat since this "encrpyted message"
could be a private message that you may not wish to share or even financial
information that can be hijacked.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Therefore, if P = NP is true, many of the current algorithms that assume P !=
NP become insecure or invalid, and people can maliciously exploit the algorithm
for their personal gains.&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;Implications of P != NP&lt;/h1&gt;
&lt;p&gt;If P != NP is true, there are some NP problems that will never be transition
into P, meaning there never will be algorithms that can solve those NP problems
in polynomial time.  &lt;/p&gt;
&lt;p&gt;Although the impact of this proof will not be as significant as P = NP since most of the the academia and the industry already assume P != NP, the proof will influence how
researchers spend their time. &lt;strong&gt;Since there cannot be a
polynomial-time solution for some NP problems, researchers would no longer have
to waste their time trying to find fast algorithms for problems in NP.&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Extra Note&lt;/h1&gt;
&lt;p&gt;NP stands for "non-deterministic polynomial time" and although P does
not have an official abbreviation, it is commonly known as "deterministic
polynomial time". A non-deterministic polynomial problem can be
solved in polynomial time with some lucky guesses. For example, finding a
least-cost cycle
that visits every node in a graph is known as a Travelling Salesman Problem,
which is notoriously difficult. However, if our solution algorithm makes certain
smart/lucky decisions in finding the path, the optimal path could be found in
polynomial time.&lt;/p&gt;
&lt;p&gt;Meanwhile, the P problem can find a solution in polynomial time without depending on luck. As mentioned
before, since P is in NP under P != NP, P problems can also find polynomial-time
solution with some lucky guesses.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Don Han</dc:creator><pubDate>Sat, 30 May 2015 00:00:00 -0700</pubDate><guid>tag:don-han.github.io,2015-05-30:website/intro-to-p-vs-np.html</guid><category>intro-to</category><category>theory-of-computer-science</category></item><item><title>[HOW-TO] Make a website with GitHub Pages and Pelican</title><link>https://don-han.github.io/website/how-to-make-a-website-with-github-pages-and-pelican.html</link><description>&lt;hr /&gt;
&lt;p&gt;This article is intended for audience who has some knowledge on GitHub Pages and
Pelican, but was unable to integrate two successfully. Therefore, many steps
below assume you are fully aware of the consequence and the context of commands
to be executed. Since there are already many instructional guides for GitHub
Pages and Pelican, my main focus will be on how to incorporate Pelican into
GitHub Pages.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Although GitHub Pages and Pelican are very easy to use on their own, I had a
trouble integrating them together. The main difficulty was GitHub Pages trying
to build a website with files on root when Pelican generates the website on
subfolder called 'output'. &lt;/p&gt;
&lt;p&gt;Some bloggers suggested creating two separate GitHub repos: one for entire files
and another for just the output folder. However, I did not like the idea of
having to keep track of two different repositories for one project. &lt;/p&gt;
&lt;p&gt;At one point or another, I thought of moving to Jekyll which is officially
supported by GitHub Pages, but I like Python more, so I decided to stick to it.
After a few hours of struggle, this is what I came to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create your GitHub repo that will store your website. It doesn't have to
follow the &lt;code&gt;username.github.io&lt;/code&gt; format (my repo is named &lt;code&gt;website&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make .gitignore with&lt;/p&gt;
&lt;p&gt;&lt;code&gt;output/&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a skeleton project with &lt;code&gt;pelican-quickstart&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After you finish writing contents and customizing, you can generate
your site with &lt;code&gt;pelican content&lt;/code&gt;. By default, this will create your website
structure on 'output' folder.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install ghp-import (&lt;code&gt;pip install ghp-import&lt;/code&gt;) and do &lt;code&gt;ghp-import output&lt;/code&gt;. To quote the creator, it is "a
script that can copy a directory to the gh-pages branch of the repository." More information about
ghp-import &lt;a href="https://github.com/davisp/ghp-import"&gt;here&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, to update your changes online, &lt;code&gt;git push origin gh-pages&lt;/code&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, &lt;code&gt;git add .&lt;/code&gt; and &lt;code&gt;git commit -m "your message"&lt;/code&gt; on project's root
directory and push it to master with &lt;code&gt;git push origin master&lt;/code&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, your website will be hosted on
https://&lt;code&gt;username&lt;/code&gt;.github.io/&lt;code&gt;project_name&lt;/code&gt;. Replace &lt;code&gt;username&lt;/code&gt; and
&lt;code&gt;repo_name&lt;/code&gt; with your own GitHub username and repository name, respectively. &lt;/p&gt;
&lt;p&gt;The main idea is to store all your code in one repository but divide generating
source code and the output folder into two different branches. The source code
will be stored in the master branch while the output folder will be stored in
gh-pages which is used to render the website.&lt;/p&gt;
&lt;p&gt;When you want to make further changes, you can repeat process 4~7 until you are
satisfied.  Also, 5 and 6 could be combined by &lt;code&gt;ghp-import -p output&lt;/code&gt;. &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Don Han</dc:creator><pubDate>Mon, 18 May 2015 00:00:00 -0700</pubDate><guid>tag:don-han.github.io,2015-05-18:website/how-to-make-a-website-with-github-pages-and-pelican.html</guid><category>how-to</category><category>web-dev</category></item></channel></rss>