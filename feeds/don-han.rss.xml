<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Anything Technical</title><link>http://don-han.com/</link><description></description><atom:link href="http://don-han.com/feeds/don-han.rss.xml" rel="self"></atom:link><lastBuildDate>Sun, 09 Aug 2015 00:00:00 -0700</lastBuildDate><item><title>[intro-to] Bash Parallel Programming</title><link>http://don-han.com/bash-parallel-programming.html</link><description>&lt;p&gt;Parallel programming basically means writing scripts that can process multiple
tasks at the same. This is in contrast to running scripts in a serial order which requires the
previous tasks to be completed before moving onto the next.&lt;/p&gt;
&lt;p&gt;Parallelization can be useful for boosting the performance, but it requires the tasks
that are going to be parallelized to be independent of one another. Therefore, in
this tutorial, we will refer to the function &lt;code&gt;do-something&lt;/code&gt; as a task that can
be safely run in parallel. For didactic purpose, we define &lt;code&gt;do-something&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;function&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;-something&lt;span class="o"&gt;(){&lt;/span&gt;
    sleep &lt;span class="nv"&gt;$1&lt;/span&gt;
    &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$1&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There are several ways of parallelizing a bash script, and each has its own pros
and cons.&lt;/p&gt;
&lt;p&gt;1.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="k"&gt;$(&lt;/span&gt;seq &lt;span class="m"&gt;5&lt;/span&gt; 1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="k"&gt;do&lt;/span&gt;-something &lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is the simplest form of parallelization in bash. &lt;code&gt;&amp;amp;&lt;/code&gt; forks each
&lt;code&gt;do-something&lt;/code&gt; task to the background every time it's called.&lt;/p&gt;
&lt;p&gt;If you run this parallel script, your output should look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Even though our script runs from 5 to 1, &lt;code&gt;do-something&lt;/code&gt; task with the shortest sleeping time gets finished first.&lt;/p&gt;
&lt;p&gt;Also, note the speed improvement. Our serial script runs in &lt;code&gt;5+4+3+2+1=15&lt;/code&gt;
seconds while our parallel should theoretically run in 5 seconds. That's 3 times performance improvement by just attaching &lt;code&gt;&amp;amp;&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;However, there is one critical problem. Imagine, instead of looping through 5 iterations, your script has to loop through 5000 iterations, and your &lt;code&gt;do-something&lt;/code&gt; does something far more intensive. Then, your &lt;code&gt;&amp;amp;&lt;/code&gt; can easily overload the server. Our next method serves to prevent that.&lt;/p&gt;
&lt;p&gt;ADVATAGE: simple&lt;/p&gt;
&lt;p&gt;DISADVANTAGE: can potentially overload the system&lt;/p&gt;
&lt;p&gt;2.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;wait_turn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4
&lt;span class="nv"&gt;j&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="k"&gt;$(&lt;/span&gt;seq &lt;span class="m"&gt;10&lt;/span&gt; 1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="k"&gt;do&lt;/span&gt;-something &lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt;j++ % &lt;span class="nv"&gt;wait_turn&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; 0&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nb"&gt;wait&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="nb"&gt;wait&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;after loop&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Running this, our result should look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;7
8
9
10
3
4
5
6
1
2
after loop
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Can you see the pattern?&lt;/p&gt;
&lt;p&gt;Once our &lt;code&gt;wait&lt;/code&gt; function is called, the shell "waits" until all background tasks
are finished. In this case, a batch of four tasks are forked into the background at a time as specified by &lt;code&gt;wait_turn&lt;/code&gt;, and the script waits until all four processes are complete. &lt;/p&gt;
&lt;p&gt;The value of &lt;code&gt;wait_turn&lt;/code&gt; has been chosen arbitrarily, so you can fiddle with it to find the right number for your own script. Usually, the value is a multiple of the number of the cores you have.&lt;/p&gt;
&lt;p&gt;A keen observer might have noted the another &lt;code&gt;wait&lt;/code&gt; function after the function.
To illustrate its need, consider a similar script without the after-loop &lt;code&gt;wait&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;wait_turn&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4
&lt;span class="nv"&gt;j&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;1
&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="k"&gt;$(&lt;/span&gt;seq &lt;span class="m"&gt;10&lt;/span&gt; 1&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="k"&gt;do&lt;/span&gt;-something &lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="p"&gt;&amp;amp;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;((&lt;/span&gt;j++ % &lt;span class="nv"&gt;wait_turn&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; 0&lt;span class="o"&gt;))&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;then&lt;/span&gt;
        &lt;span class="nb"&gt;wait&lt;/span&gt;
&lt;span class="nb"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;after loop&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Before scrolling down, think what this would output.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;7
8
9
10
3
4
5
6
after loop
1
2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice how our "after loop" string comes before &lt;code&gt;do-something 1&lt;/code&gt; and &lt;code&gt;do-something 2&lt;/code&gt; is
processed. This could be critical if you have an after-loop code that needs the
for-loop to completely finish. Likewise, apply &lt;code&gt;wait&lt;/code&gt; fucntion after the for-loop for the first method if necessary.&lt;/p&gt;
&lt;p&gt;Yet, even this method can be restrictive. Consider a case where the total time
of task completion varies greatly. For our example above, say every fifth tasks
(&lt;code&gt;do-something 5&lt;/code&gt;, &lt;code&gt;do-something 10&lt;/code&gt;), for some odd reason, takes tremendous
amount of time to complete instead of mere 5 or 10 seconds, respectively. If we
run our script again under this new condition, we can see that our script runs
very inefficiently because for our first batch, even though tasks 7, 8, 9 are
already completed, they would have to wait for one task, &lt;code&gt;do-something 10&lt;/code&gt; to
finish! Likewise, for our second batch, the threads that were working on tasks
3, 4, and 6 are idling because they cannot move forward until &lt;code&gt;do-something 5&lt;/code&gt;
completes. In other words, if the batch contains an unusually slow task, it becomes
the bottle neck and slows down the entire process, almost defeating the purpose
of parallelism.&lt;/p&gt;
&lt;p&gt;ADVANTAGE: parallelization without overloading the system&lt;/p&gt;
&lt;p&gt;DISADVANTAGE: bottlenecks occur and can potentially slow down the entire process&lt;/p&gt;
&lt;p&gt;3.&lt;/p&gt;
&lt;p&gt;Fortunately, UNIX/LINUX comes with a command called
&lt;a href="https://en.wikipedia.org/wiki/Xargs"&gt;&lt;code&gt;xargs&lt;/code&gt;&lt;/a&gt; which whips idling tasks back to
work. . &lt;code&gt;xargs&lt;/code&gt; is not specifically designed to be used for parallelization, but
it comes with a handy &lt;code&gt;-P&lt;/code&gt; flag which defines the maximum number of processes that can run at
a time. &lt;code&gt;xargs&lt;/code&gt; is extremely flexible, so I will not go into too much details in
this article, but I will cover the basics.&lt;/p&gt;
&lt;p&gt;For example,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;seq &lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; xargs -n1 -P4 -I &lt;span class="o"&gt;{}&lt;/span&gt; bash -c &lt;span class="s2"&gt;&amp;quot;sleep {}; echo {};&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To break it down, I give the input ranging from 10 to 1. Then, &lt;code&gt;xargs&lt;/code&gt; separates
the input into indiviual pieces (as specified by -n1, meaning take at most one
argument). The big &lt;code&gt;-P&lt;/code&gt; flag as mentioned is what gives the parallelization
ability. Without it, the &lt;code&gt;xargs&lt;/code&gt; runs the command in a serial manner. After we
set the variable to &lt;code&gt;{}&lt;/code&gt;, &lt;code&gt;-I&lt;/code&gt; replaces all ocurrences of &lt;code&gt;{}&lt;/code&gt; in the command
with the input chunk, which in our case are individual numbers. Finally, &lt;code&gt;xargs&lt;/code&gt;
runs the bash, which, in turn, executes the string with all &lt;code&gt;{}&lt;/code&gt; replaced with
input chunks.&lt;/p&gt;
&lt;p&gt;The above snippet produces:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;7
8
9
10
5
4
3
6
1
2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As we have seen with #2, since we have limited to the four processes, only upto 4 tasks are processed at a time. However, if you take a look at the second batch, you will see that the numbers are not ordered as before. This is because &lt;code&gt;xargs&lt;/code&gt; assigns tasks as soon as processes becomes available.&lt;/p&gt;
&lt;p&gt;Indeed, if we give as many processes as there are inputs, all processes will be handled at the same time as we would expect.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;seq &lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; xargs -n1 -P10 -I &lt;span class="o"&gt;{}&lt;/span&gt; bash -c &lt;span class="s2"&gt;&amp;quot;sleep {}; echo {};&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;which rightly produces&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;1
2
3
4
5
6
7
8
9
10
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;xargs&lt;/code&gt; should be sufficient for most users under most usage cases. Other than the fact that it's a tad bit more complicated than the first two methods I introduced above, &lt;code&gt;xargs&lt;/code&gt; provides an efficient, easy way of implementing a parallel script.&lt;/p&gt;
&lt;p&gt;ADVANTAGE: eliminates bottleneck&lt;/p&gt;
&lt;p&gt;DISADVANTAGE: none for most users. See #4 for more&lt;/p&gt;
&lt;p&gt;4. &lt;/p&gt;
&lt;p&gt;However, for some users, they might need something more powerful, in which case,
I introduce you &lt;a href="http://www.gnu.org/software/parallel/"&gt;GNU Parallel&lt;/a&gt;.
Thankfully, GNU Parallel already detailed
&lt;a href="https://www.gnu.org/software/parallel/man.html#DIFFERENCES-BETWEEN-xargs-AND-GNU-Parallel"&gt;reasons why you might want to switch over&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;parallel&lt;/code&gt; equivalent of &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;seq &lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; xargs -P4 -I &lt;span class="o"&gt;{}&lt;/span&gt; bash -c &lt;span class="s2"&gt;&amp;quot;sleep {}; echo {};&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;seq &lt;span class="m"&gt;10&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="p"&gt;|&lt;/span&gt; parallel -P4 &lt;span class="s2"&gt;&amp;quot;sleep {}; echo {};&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can see that &lt;code&gt;parallel&lt;/code&gt;syntax is a lot simpler than &lt;code&gt;xargs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;ADVANTAGE: refer to &lt;a href="https://www.gnu.org/software/parallel/man.html#DIFFERENCES-BETWEEN-xargs-AND-GNU-Parallel"&gt;the comparison between xargs and GNU Parallel&lt;/a&gt;; to name a few, flexibility and simplicity&lt;/p&gt;
&lt;p&gt;DISADVANTAGE: external dependency&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Don Han</dc:creator><pubDate>Sun, 09 Aug 2015 00:00:00 -0700</pubDate><guid>tag:don-han.com,2015-08-09:bash-parallel-programming.html</guid><category>intro-to</category><category>bash</category><category>parallel programming</category></item><item><title>[intro-to] P vs. NP</title><link>http://don-han.com/intro-to-p-vs-np.html</link><description>&lt;p&gt;NOTE: The following article is intended as a gentle introduction
for the subject, so I have intentionally left out some information that I considered
is out of scope. However, if you are familiar with the subject and if you think
I presented &lt;em&gt;factually wrong&lt;/em&gt; statements, I will greatly appreciate an email
with corrections. Also, if you are confused with my explanation, please feel free to
send me an email with details of where you are confused, so I can make it a bit
more clear. &lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;What exactly are P and NP? Why do we need them?&lt;/h1&gt;
&lt;p&gt;In order to understand the P vs. NP problem, we must understand P and NP first. P
and NP rose from the necessity of matheticians and computer scientists to
describe how much resources, such as time, are needed to solve a decision
problem. A decision problem is defined as any problem that given an input can
determine or &lt;em&gt;decide&lt;/em&gt; with "yes" or "no" answer. For example, given a path and a
budget cost as inputs, the decision problem might output "yes" if the path cost
is equal to or lower than the budget cost. Likewise, the decision problem might output "no" if the path cost is higher than the budget cost. &lt;/p&gt;
&lt;p&gt;To be more precise, P problems are a set of decision problems that can be solved in polynomial
time &lt;em&gt;and&lt;/em&gt; verified in polynomial time. For the decision problem used as an
example above, our verification algorithm may sum up the cost of edges in linear time ( O(n) ) to
compare it with the budget cost while the search algorithms such as DFS/BFS
obtain the path in linear time as wel. On the other hand, NP problems are
a set of decision problems which can be verified in polynomial time, but &lt;em&gt;not
necessarily&lt;/em&gt; solved in polynomial time. &lt;/p&gt;
&lt;p&gt;Although a common misunderstanding is to
conceptualize NP as "&lt;em&gt;not&lt;/em&gt; P", such notion is greatly misleading. Note that NP
problems may or may not be solved in polynomial time. Therefore, NP and P are
not mutually exclusive classes. Rather, P is a subset of NP; all P problems
automatically qualify as NP problems since all P problems satisfy
polynomial-time verification &lt;em&gt;as well as&lt;/em&gt; polynomial-time solution, and since NP
problems only need to fulfill polynomial-time verification, all P problems are NP problems as well.&lt;/p&gt;
&lt;p&gt;For more technical details between P and NP, refer to the extra note.&lt;/p&gt;
&lt;h1&gt;P versus NP&lt;/h1&gt;
&lt;p&gt;Now we can tackle P vs. NP problem. The question simiply asks if P equals to NP
or not. In other words, the problem asks, if a
problem can be verified in a polynomial time, can the problem be solved in
a polynomial time &lt;em&gt;all the time&lt;/em&gt;? That is, are some NP problems inherently
difficult or even impossible to solve in polynomial time, or have we just
not found the fast algorithms &lt;em&gt;yet&lt;/em&gt;? So far, no official proof has been
recognized by the Clay Mathematics Institute, which promises to reward
one million dollars to anyone who can solve the P vs. NP problem. Although the question is simple, the implication is significant. &lt;/p&gt;
&lt;h1&gt;Implications of P = NP&lt;/h1&gt;
&lt;p&gt;If P = NP is proven, then this implies that all problems that can be
verified in polynomial time can also be solved in polynomial time as well. The
impact extends beyond the academic world since many industrial algorithms including
cryptography are written under the assumption that P != NP.&lt;/p&gt;
&lt;p&gt;For example, RSA, which is a widely used cryptosystem to secure data
transmission, exploits P != NP by designing a decryption algorithm that runs in
polynomial time only for those who have the right access (known as a private key). If you
do not have the private key (meaning you do not have access), you would need to solve
the RSA problem, which is a NP problem since there is no known algorithm that
can decrypt encryption in polynomial time.&lt;/p&gt;
&lt;p&gt;However, if P = NP is proven true, this implies that there exists some
algorithms that can solve the RSA problem in polynomial time, meaning any
encrypted message can be decrypted easily by even those who should not have
access if they can find the polynomial-time decryption algorithm, which is not
supposed to exist under the P != NP assumption. &lt;/p&gt;
&lt;p&gt;Obviously, this is a significant security threat since this "encrpyted message"
could be a private message that you may not wish to share or even financial
information that can be hijacked.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Therefore, if P = NP is true, many of the current algorithms that assume P !=
NP become insecure or invalid, and people can maliciously exploit the algorithm
for their personal gains.&lt;/strong&gt;&lt;/p&gt;
&lt;h1&gt;Implications of P != NP&lt;/h1&gt;
&lt;p&gt;If P != NP is true, there are some NP problems that will never be transition
into P, meaning there never will be algorithms that can solve those NP problems
in polynomial time.  &lt;/p&gt;
&lt;p&gt;Although the impact of this proof will not be as significant as P = NP since most of the the academia and the industry already assume P != NP, the proof will influence how
researchers spend their time. &lt;strong&gt;Since there cannot be a
polynomial-time solution for some NP problems, researchers would no longer have
to waste their time trying to find fast algorithms for problems in NP.&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;h1&gt;Extra Note&lt;/h1&gt;
&lt;p&gt;NP stands for "non-deterministic polynomial time" and although P does
not have an official abbreviation, it is commonly known as "deterministic
polynomial time". A non-deterministic polynomial problem can be
solved in polynomial time with some lucky guesses. For example, finding a
least-cost cycle
that visits every node in a graph is known as a Travelling Salesman Problem,
which is notoriously difficult. However, if our solution algorithm makes certain
smart/lucky decisions in finding the path, the optimal path could be found in
polynomial time.&lt;/p&gt;
&lt;p&gt;Meanwhile, the P problem can find a solution in polynomial time without depending on luck. As mentioned
before, since P is in NP under P != NP, P problems can also find polynomial-time
solution with some lucky guesses.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Don Han</dc:creator><pubDate>Sat, 30 May 2015 00:00:00 -0700</pubDate><guid>tag:don-han.com,2015-05-30:intro-to-p-vs-np.html</guid><category>intro-to</category><category>theory-of-computer-science</category></item><item><title>[how-to] Make a website with GitHub Pages and Pelican</title><link>http://don-han.com/how-to-make-a-website-with-github-pages-and-pelican.html</link><description>&lt;hr /&gt;
&lt;p&gt;This article is intended for audience who has some knowledge on GitHub Pages and
Pelican, but was unable to integrate two successfully. Therefore, many steps
below assume you are fully aware of the consequence and the context of commands
to be executed. Since there are already many instructional guides for GitHub
Pages and Pelican, my main focus will be on how to incorporate Pelican into
GitHub Pages.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;UPDATE [2015-09-22]: It seems like running &lt;code&gt;make github&lt;/code&gt; on your source branch achieves 4-6 steps for you. However, you will still need to do 7 if you want to save your changes. Also, although automation is nice, I advise you to go through the steps manually for the first few weeks if you are new to Pelican to understand what actually is going on under &lt;code&gt;make github&lt;/code&gt;. If there is a problem with the automation, you will have better luck if you already understand the process.&lt;/h2&gt;
&lt;p&gt;Although GitHub Pages and Pelican are very easy to use on their own, I had a
trouble integrating them together. The main difficulty was GitHub Pages trying
to build a website with files on root when Pelican generates the website on
subfolder called 'output'. &lt;/p&gt;
&lt;p&gt;Some bloggers suggested creating two separate GitHub repos: one for entire files
and another for just the output folder. However, I did not like the idea of
having to keep track of two different repositories for one project. &lt;/p&gt;
&lt;p&gt;At one point or another, I thought of moving to Jekyll which is officially
supported by GitHub Pages, but I like Python more, so I decided to stick to it.
After a few hours of struggle, this is what I came to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Create your GitHub repo that will store your website. It doesn't have to
follow the &lt;code&gt;username.github.io&lt;/code&gt; format (my repo is named &lt;code&gt;website&lt;/code&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Make .gitignore with&lt;/p&gt;
&lt;p&gt;&lt;code&gt;output/&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Create a skeleton project with &lt;code&gt;pelican-quickstart&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;After you finish writing contents and customizing, you can generate
your site with &lt;code&gt;pelican content&lt;/code&gt;. By default, this will create your website
structure on 'output' folder.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install ghp-import (&lt;code&gt;pip install ghp-import&lt;/code&gt;) and do &lt;code&gt;ghp-import output&lt;/code&gt;. To quote the creator, it is "a
script that can copy a directory to the gh-pages branch of the repository." More information about
ghp-import &lt;a href="https://github.com/davisp/ghp-import"&gt;here&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, to update your changes online, &lt;code&gt;git push origin gh-pages&lt;/code&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, &lt;code&gt;git add .&lt;/code&gt; and &lt;code&gt;git commit -m "your message"&lt;/code&gt; on project's root
directory and push it to master with &lt;code&gt;git push origin master&lt;/code&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At this point, your website will be hosted on
https://&lt;code&gt;username&lt;/code&gt;.github.io/&lt;code&gt;project_name&lt;/code&gt;. Replace &lt;code&gt;username&lt;/code&gt; and
&lt;code&gt;repo_name&lt;/code&gt; with your own GitHub username and repository name, respectively. &lt;/p&gt;
&lt;p&gt;The main idea is to store all your code in one repository but divide generating
source code and the output folder into two different branches. The source code
will be stored in the master branch while the output folder will be stored in
gh-pages which is used to render the website.&lt;/p&gt;
&lt;p&gt;When you want to make further changes, you can repeat process 4~7 until you are
satisfied.  Also, 5 and 6 could be combined by &lt;code&gt;ghp-import -p output&lt;/code&gt;. &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Don Han</dc:creator><pubDate>Mon, 18 May 2015 00:00:00 -0700</pubDate><guid>tag:don-han.com,2015-05-18:how-to-make-a-website-with-github-pages-and-pelican.html</guid><category>how-to</category><category>web-dev</category></item></channel></rss>